global {
  appName = "ubas_nu_test"
  appMode = "stream"
  spark.sql.warehouse.dir = "/user/hive/warehouse/"
  spark.serializer = "org.apache.spark.serializer.KryoSerializer"
  hive.exec.dynamic.partition = "true"
  hive.exec.dynamic.partition.mode = "nonstrict"
}
input {
 u_opr_record_nu {
  format = "kafka"
  processMode = "stream"
  kafka.bootstrap.servers = "kafka.daikuan.qihoo.net:9092"
  subscribe = "u_opr_record_nu"
  startingOffsets = "latest"
  maxOffsetsPerTrigger = "100000"
 }
}
compute {
 u_opr_record_nu_tmp1 {
  dependencies = "u_opr_record_nu"
  sql = "select CAST(value AS STRING) value from u_opr_record_nu"
 }
 u_opr_record_nu_tmp2 {
  dependencies = "u_opr_record_nu_tmp1"
  sql = "select get_json_object(value, '$.body') body from u_opr_record_nu_tmp1"
 }
 u_opr_record_nu_tmp3 {
  dependencies = "u_opr_record_nu_tmp2"
  sql = """select get_json_object(body, '$.oprNo') as opr_no,
           get_json_object(body, '$.flowNo') as flow_no,
           get_json_object(body, '$.bizCode') as biz_code,
           get_json_object(body, '$.eventCode') as event_code,
           get_json_object(body, '$.eventType') as event_type,
           get_json_object(body, '$.oprTime') as opr_time,
           get_json_object(body, '$.serverTime') as server_time,
           get_json_object(body, '$.deviceIp') as device_ip,
           get_json_object(body, '$.requestIp') as request_ip,
           get_json_object(body, '$.canvasFingerprint') as canvas_fingerprint,
           get_json_object(body, '$.deviceFingerprint') as device_fingerprint,
           get_json_object(body, '$.mobileNo') as mobile_no,
           get_json_object(body, '$.sourceType') as source_type,
           get_json_object(body, '$.hostApp') as host_app,
           get_json_object(body, '$.channelSource') as channel_source,
           get_json_object(body, '$.subChannel') as sub_channel,
           get_json_object(body, '$.activityInfo') as activity_info,
           get_json_object(body, '$.utmContent') as utm_content,
           get_json_object(body, '$.utmTerm') as utm_term,
           get_json_object(body, '$.pageName') as page_name,
           get_json_object(body, '$.latitude') as latitude,
           get_json_object(body, '$.longitude') as longitude,
           get_json_object(body, '$.country') as country,
           get_json_object(body, '$.area') as area,
           get_json_object(body, '$.region') as region,
           get_json_object(body, '$.city') as city,
           get_json_object(body, '$.county') as county,
           get_json_object(body, '$.countryId') as country_id,
           get_json_object(body, '$.areaId') as area_id,
           get_json_object(body, '$.regionId') as region_id,
           get_json_object(body, '$.cityId') as city_id,
           get_json_object(body, '$.countyId') as county_id,
           get_json_object(body, '$.isp') as isp,
           get_json_object(body, '$.ispId') as isp_id,
           get_json_object(body, '$.detailAddress') as detail_address,
           get_json_object(body, '$.bizData') as biz_data,
           from_unixtime(unix_timestamp()) as date_created,
           'sys' as created_by,
           from_unixtime(unix_timestamp()) as date_updated,
           'sys' as updated_by,
           '' as extend_field1,
           '' as extend_field2,
           '' as extend_field3,
           '' as extend_field4,
           get_json_object(body, '$.deviceInfo') as device_info,
           get_json_object(body, '$.mobileModel') as mobile_model,
           get_json_object(body, '$.osType') as os_type,
           get_json_object(body, '$.mobileNoMd5X') as mobile_no_md5x,
           current_date as partitions from u_opr_record_nu_tmp2"""
 }
}

output {
 output1 {
  format = "hive"
  processMode = "stream"
  dependencies = "u_opr_record_nu_tmp3"
  sql = "select * from u_opr_record_nu_tmp3"
  triggerType = "processingTime"
  triggerTime = "60 seconds"
  checkpointLocation = "hdfs:///user/qiuchen/spark/streaming/ubas_nu_test"
  outputMode = "append"
  saveMode = "append"
  destTable = "ods_rc.u_opr_record_nu_part"
 }
}